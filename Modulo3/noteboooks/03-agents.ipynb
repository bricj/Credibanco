{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "43061497",
   "metadata": {},
   "source": [
    "# Introduccion Agentes con Langchain"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "66b6d093",
   "metadata": {},
   "source": [
    "LangChain es una de las bibliotecas de código abierto más populares para ingenieros de inteligencia artificial. Su objetivo es abstraer la complejidad al construir software de IA, proporcionar bloques de construcción fáciles de usar y facilitar el cambio entre distintos proveedores de servicios de IA.\n",
    "\n",
    "En este ejemplo, presentaremos los Agents de LangChain, que añaden la capacidad de utilizar herramientas como búsquedas y calculadoras para completar tareas que los modelos de lenguaje tradicionales no pueden realizar. En este caso, utilizaremos el modelo gpt-4o-mini de OpenAI."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "af79febe",
   "metadata": {},
   "outputs": [],
   "source": [
    "# # Ejecutar en caso que se desee utilizar con google colab\n",
    "# !pip install -qU \\\n",
    "#   langchain-core==0.3.33 \\\n",
    "#   langchain-openai==0.3.3 \\\n",
    "#   langchain-community==0.3.16 \\\n",
    "#   google-search-results==2.4.2"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d9a53eb1",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "id": "ee30f17d",
   "metadata": {},
   "source": [
    "## 1. Introduccion a Herramientas (Tools)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "ea0fc243",
   "metadata": {},
   "source": [
    "Las tools (herramientas) son una forma de ampliar las capacidades de nuestros modelos de lenguaje (LLM) permitiéndoles ejecutar código. Una herramienta es simplemente una función formateada de manera que nuestro agente pueda entender cómo utilizarla y luego ejecutarla. Comencemos creando algunas herramientas simples.\n",
    "\n",
    "Podemos usar el decorador @tool para convertir una función estándar de Python en una herramienta compatible con un LLM. Esta función debe incluir algunos elementos clave para lograr un rendimiento óptimo:\n",
    "\n",
    "Un docstring que describa qué hace la herramienta y cuándo debe usarse. Esto será leído por nuestro LLM o agente y le permitirá decidir cuándo y cómo utilizarla.\n",
    "\n",
    "Nombres de parámetros claros, que idealmente indiquen al LLM el propósito de cada uno. Si no es evidente, el docstring debe explicar para qué sirve el parámetro y cómo debe usarse.\n",
    "\n",
    "Anotaciones de tipo tanto para los parámetros como para el valor de retorno."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "44f76f7e",
   "metadata": {},
   "outputs": [],
   "source": [
    "from langchain_core.tools import tool\n",
    "\n",
    "@tool\n",
    "def add(x: float, y: float) -> float:\n",
    "    \"\"\"Add 'x' and 'y'.\"\"\"\n",
    "    return x + y\n",
    "\n",
    "@tool\n",
    "def multiply(x: float, y: float) -> float:\n",
    "    \"\"\"Multiply 'x' and 'y'.\"\"\"\n",
    "    return x * y\n",
    "\n",
    "@tool\n",
    "def exponentiate(x: float, y: float) -> float:\n",
    "    \"\"\"Raise 'x' to the power of 'y'.\"\"\"\n",
    "    return x ** y\n",
    "\n",
    "@tool\n",
    "def subtract(x: float, y: float) -> float:\n",
    "    \"\"\"Subtract 'x' from 'y'.\"\"\"\n",
    "    return y - x"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "72dff5dd",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "StructuredTool(name='add', description=\"Add 'x' and 'y'.\", args_schema=<class 'langchain_core.utils.pydantic.add'>, func=<function add at 0x00000221EFC53060>)"
      ]
     },
     "execution_count": 3,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "add"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "39e4adab",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "add.name='add'\n",
      "add.description=\"Add 'x' and 'y'.\"\n"
     ]
    }
   ],
   "source": [
    "print(f\"{add.name=}\\n{add.description=}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "fd49e84d",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{'description': \"Add 'x' and 'y'.\",\n",
       " 'properties': {'x': {'title': 'X', 'type': 'number'},\n",
       "  'y': {'title': 'Y', 'type': 'number'}},\n",
       " 'required': ['x', 'y'],\n",
       " 'title': 'add',\n",
       " 'type': 'object'}"
      ]
     },
     "execution_count": 5,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "add.args_schema.model_json_schema()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "5e6efc07",
   "metadata": {},
   "source": [
    "Al invocar la herramienta, una cadena JSON generada por el LLM será analizada (parseada) como JSON y luego consumida como argumentos con nombre (kwargs), de forma similar a lo siguiente:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "6d8f9c7c",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{'x': 5, 'y': 2}"
      ]
     },
     "execution_count": 7,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "import json\n",
    "\n",
    "llm_output_string = \"{\\\"x\\\": 5, \\\"y\\\": 2}\"  # this is the output from the LLM\n",
    "llm_output_dict = json.loads(llm_output_string)  # load as dictionary\n",
    "llm_output_dict"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "cdbfba2f",
   "metadata": {},
   "source": [
    "Esto luego se pasa a la función de la herramienta como kwargs (argumentos con nombre), como lo indica el operador **. El operador ** se utiliza para desempaquetar el diccionario en argumentos con nombre."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "49648df3",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "25"
      ]
     },
     "execution_count": 8,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "exponentiate.func(**llm_output_dict)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "996a6311",
   "metadata": {},
   "source": [
    "## 2. Crear un Agente"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "a29e438f",
   "metadata": {},
   "source": [
    "Vamos a construir un agente sencillo que utilice herramientas. Usaremos el LangChain Expression Language (LCEL) para construir el agente. Veremos LCEL en más detalle en el próximo capítulo, pero por ahora, lo único que necesitamos saber es que nuestro agente se construirá usando la siguiente sintaxis y componentes:\n",
    "\n",
    "```\n",
    "agent = (\n",
    "    <input parameters, including chat history and user query>\n",
    "    | <prompt>\n",
    "    | <LLM with tools>\n",
    ")\n",
    "```\n",
    "Al crear un agente, necesitamos añadir memoria conversacional para que el agente recuerde interacciones previas. Usaremos la clase más antigua ConversationBufferMemory en lugar de la más reciente RunnableWithMessageHistory, debido a que también utilizaremos el método y la clase más antiguos create_tool_calling_agent y AgentExecutor.\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "1ef70179",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\Sebastian\\AppData\\Local\\Temp\\ipykernel_24476\\3265027606.py:16: LangChainDeprecationWarning: Please see the migration guide at: https://python.langchain.com/docs/versions/migrating_memory/\n",
      "  memory = ConversationBufferMemory(\n"
     ]
    }
   ],
   "source": [
    "from langchain_core.prompts import ChatPromptTemplate, MessagesPlaceholder\n",
    "\n",
    "# Definir Prompt con el Template\n",
    "\n",
    "prompt = ChatPromptTemplate.from_messages([\n",
    "    (\"system\", \"you're a helpful assistant\"),\n",
    "    MessagesPlaceholder(variable_name=\"chat_history\"),\n",
    "    (\"human\", \"{input}\"),\n",
    "    (\"placeholder\", \"{agent_scratchpad}\"),\n",
    "])\n",
    "\n",
    "# Definir el tipo de memoria\n",
    "\n",
    "from langchain.memory import ConversationBufferMemory\n",
    "\n",
    "memory = ConversationBufferMemory(\n",
    "    memory_key=\"chat_history\",  # must align with MessagesPlaceholder variable_name\n",
    "    return_messages=True  # to return Message objects\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "022e460e",
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "from getpass import getpass\n",
    "from langchain_openai import ChatOpenAI\n",
    "\n",
    "# Definir el modelo de lenguaje (Se incluye API Key)\n",
    "\n",
    "os.environ[\"OPENAI_API_KEY\"] = os.getenv(\"OPENAI_API_KEY\") \\\n",
    "    or getpass(\"Enter your OpenAI API key: \")\n",
    "\n",
    "llm = ChatOpenAI(\n",
    "    model_name=\"gpt-4o-mini\",\n",
    "    temperature=0.0,\n",
    ")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "14eb7d78",
   "metadata": {},
   "source": [
    "Ahora inicializaremos nuestro agente. Para ello necesitamos:\n",
    "\n",
    "* llm: como ya está definido\n",
    "\n",
    "* tools: por definir (simplemente una lista de nuestras herramientas definidas previamente)\n",
    "\n",
    "* prompt: como ya está definido\n",
    "\n",
    "* memory: como ya está definido"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "eae0eb0a",
   "metadata": {},
   "outputs": [],
   "source": [
    "from langchain.agents import create_tool_calling_agent\n",
    "\n",
    "# Construir el agente en funcion del modelo de lenguaje, herramientas y prompt\n",
    "\n",
    "tools = [add, subtract, multiply, exponentiate]\n",
    "\n",
    "agent = create_tool_calling_agent(\n",
    "    llm=llm, tools=tools, prompt=prompt\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "id": "d4bc00c3",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[ToolAgentAction(tool='multiply', tool_input={'x': 10.7, 'y': 7.68}, log=\"\\nInvoking: `multiply` with `{'x': 10.7, 'y': 7.68}`\\n\\n\\n\", message_log=[AIMessage(content='', additional_kwargs={'tool_calls': [{'id': 'call_hinLdDgweN4rhnht16qRwXQ8', 'function': {'arguments': '{\"x\":10.7,\"y\":7.68}', 'name': 'multiply'}, 'type': 'function'}], 'refusal': None}, response_metadata={'token_usage': {'completion_tokens': 21, 'prompt_tokens': 146, 'total_tokens': 167, 'completion_tokens_details': {'accepted_prediction_tokens': 0, 'audio_tokens': 0, 'reasoning_tokens': 0, 'rejected_prediction_tokens': 0}, 'prompt_tokens_details': {'audio_tokens': 0, 'cached_tokens': 0}}, 'model_name': 'gpt-4o-mini-2024-07-18', 'system_fingerprint': 'fp_dbaca60df0', 'finish_reason': 'tool_calls', 'logprobs': None}, id='run-6f5b3b9d-2701-4215-9982-66d014733b8e-0', tool_calls=[{'name': 'multiply', 'args': {'x': 10.7, 'y': 7.68}, 'id': 'call_hinLdDgweN4rhnht16qRwXQ8', 'type': 'tool_call'}], usage_metadata={'input_tokens': 146, 'output_tokens': 21, 'total_tokens': 167, 'input_token_details': {'audio': 0, 'cache_read': 0}, 'output_token_details': {'audio': 0, 'reasoning': 0}})], tool_call_id='call_hinLdDgweN4rhnht16qRwXQ8')]"
      ]
     },
     "execution_count": 14,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Exponer respuesta del agente\n",
    "\n",
    "agent.invoke({\n",
    "    \"input\": \"what is 10.7 multiplied by 7.68?\",\n",
    "    \"chat_history\": memory.chat_memory.messages,\n",
    "    \"intermediate_steps\": []  # agent will append it's internal steps here\n",
    "})"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "40accab8",
   "metadata": {},
   "source": [
    "Aquí podemos ver que el LLM ha generado que debemos usar la herramienta multiply y que la entrada para la herramienta debe ser {\"x\": 10.7, \"y\": 7.68}. Sin embargo, la herramienta no se ejecuta. Para que eso ocurra, necesitamos un bucle de ejecución del agente, el cual se encargará de las múltiples iteraciones de generación, llamada a herramienta, generación, etc.\n",
    "\n",
    "Usamos la clase AgentExecutor para manejar el bucle de ejecución."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "id": "9071ad5b",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "\n",
      "\u001b[1m> Entering new AgentExecutor chain...\u001b[0m\n",
      "\u001b[32;1m\u001b[1;3m\n",
      "Invoking: `multiply` with `{'x': 10.7, 'y': 7.68}`\n",
      "\n",
      "\n",
      "\u001b[0m\u001b[38;5;200m\u001b[1;3m82.17599999999999\u001b[0m\u001b[32;1m\u001b[1;3m10.7 multiplied by 7.68 is approximately 82.18.\u001b[0m\n",
      "\n",
      "\u001b[1m> Finished chain.\u001b[0m\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "{'input': 'what is 10.7 multiplied by 7.68?',\n",
       " 'chat_history': [HumanMessage(content='what is 10.7 multiplied by 7.68?', additional_kwargs={}, response_metadata={}),\n",
       "  AIMessage(content='10.7 multiplied by 7.68 is approximately 82.18.', additional_kwargs={}, response_metadata={}),\n",
       "  HumanMessage(content='what is 10.7 multiplied by 7.68?', additional_kwargs={}, response_metadata={}),\n",
       "  AIMessage(content='10.7 multiplied by 7.68 is approximately 82.18.', additional_kwargs={}, response_metadata={}),\n",
       "  HumanMessage(content='what is 10.7 multiplied by 7.68?', additional_kwargs={}, response_metadata={}),\n",
       "  AIMessage(content='10.7 multiplied by 7.68 is approximately 82.18.', additional_kwargs={}, response_metadata={})],\n",
       " 'output': '10.7 multiplied by 7.68 is approximately 82.18.'}"
      ]
     },
     "execution_count": 17,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "from langchain.agents import AgentExecutor\n",
    "\n",
    "agent_executor = AgentExecutor(\n",
    "    agent=agent,\n",
    "    tools=tools,\n",
    "    memory=memory,\n",
    "    verbose=True\n",
    ")\n",
    "\n",
    "# Ahora probemos la misma consulta con el ejecutor. Nota que el parámetro intermediate_steps que añadimos \n",
    "# antes ya no es necesario, ya que el ejecutor lo maneja internamente.\n",
    "\n",
    "agent_executor.invoke({\n",
    "    \"input\": \"what is 10.7 multiplied by 7.68?\",\n",
    "    \"chat_history\": memory.chat_memory.messages,\n",
    "})"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "id": "fdc97d19",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Ejecucion para validar respuesta: 82.17599999999999\n"
     ]
    }
   ],
   "source": [
    "print(f'Ejecucion para validar respuesta: {10.7*7.68}')"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "01e7982c",
   "metadata": {},
   "source": [
    "### 2.1 Validar el uso de memoria las herramientas"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "id": "625e088b",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "\n",
      "\u001b[1m> Entering new AgentExecutor chain...\u001b[0m\n",
      "\u001b[32;1m\u001b[1;3mNice to meet you, Bric! How can I assist you today?\u001b[0m\n",
      "\n",
      "\u001b[1m> Finished chain.\u001b[0m\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "{'input': 'My name is bric',\n",
       " 'chat_history': [HumanMessage(content='what is 10.7 multiplied by 7.68?', additional_kwargs={}, response_metadata={}),\n",
       "  AIMessage(content='10.7 multiplied by 7.68 is approximately 82.18.', additional_kwargs={}, response_metadata={}),\n",
       "  HumanMessage(content='what is 10.7 multiplied by 7.68?', additional_kwargs={}, response_metadata={}),\n",
       "  AIMessage(content='10.7 multiplied by 7.68 is approximately 82.18.', additional_kwargs={}, response_metadata={}),\n",
       "  HumanMessage(content='what is 10.7 multiplied by 7.68?', additional_kwargs={}, response_metadata={}),\n",
       "  AIMessage(content='10.7 multiplied by 7.68 is approximately 82.18.', additional_kwargs={}, response_metadata={}),\n",
       "  HumanMessage(content='My name is bric', additional_kwargs={}, response_metadata={}),\n",
       "  AIMessage(content='Nice to meet you, Bric! How can I assist you today?', additional_kwargs={}, response_metadata={})],\n",
       " 'output': 'Nice to meet you, Bric! How can I assist you today?'}"
      ]
     },
     "execution_count": 20,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "name = input()\n",
    "\n",
    "agent_executor.invoke({\n",
    "    \"input\": f\"My name is {name}\",\n",
    "    \"chat_history\": memory\n",
    "})"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "id": "2df0ed88",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "\n",
      "\u001b[1m> Entering new AgentExecutor chain...\u001b[0m\n",
      "\u001b[32;1m\u001b[1;3m\n",
      "Invoking: `add` with `{'x': 9, 'y': 10}`\n",
      "\n",
      "\n",
      "\u001b[0m\u001b[36;1m\u001b[1;3m19.0\u001b[0m\u001b[32;1m\u001b[1;3m\n",
      "Invoking: `multiply` with `{'x': 4, 'y': 2}`\n",
      "\n",
      "\n",
      "\u001b[0m\u001b[38;5;200m\u001b[1;3m8.0\u001b[0m\u001b[32;1m\u001b[1;3m\n",
      "Invoking: `exponentiate` with `{'x': 11, 'y': 3}`\n",
      "\n",
      "\n",
      "\u001b[0m\u001b[36;1m\u001b[1;3m1331.0\u001b[0m\u001b[32;1m\u001b[1;3mThe result of \\( (9 + 10 - 4 \\times 2)^3 \\) is \\( 1331 \\).\u001b[0m\n",
      "\n",
      "\u001b[1m> Finished chain.\u001b[0m\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "{'input': 'What is nine plus 10, minus 4 * 2 adn the result to the power of 3',\n",
       " 'chat_history': [HumanMessage(content='what is 10.7 multiplied by 7.68?', additional_kwargs={}, response_metadata={}),\n",
       "  AIMessage(content='10.7 multiplied by 7.68 is approximately 82.18.', additional_kwargs={}, response_metadata={}),\n",
       "  HumanMessage(content='what is 10.7 multiplied by 7.68?', additional_kwargs={}, response_metadata={}),\n",
       "  AIMessage(content='10.7 multiplied by 7.68 is approximately 82.18.', additional_kwargs={}, response_metadata={}),\n",
       "  HumanMessage(content='what is 10.7 multiplied by 7.68?', additional_kwargs={}, response_metadata={}),\n",
       "  AIMessage(content='10.7 multiplied by 7.68 is approximately 82.18.', additional_kwargs={}, response_metadata={}),\n",
       "  HumanMessage(content='My name is bric', additional_kwargs={}, response_metadata={}),\n",
       "  AIMessage(content='Nice to meet you, Bric! How can I assist you today?', additional_kwargs={}, response_metadata={}),\n",
       "  HumanMessage(content='What is nine plus 10, minus 4 * 2, to the power of 3', additional_kwargs={}, response_metadata={}),\n",
       "  AIMessage(content='The result of \\\\( 9 + 10 - 4 \\\\times 2^3 \\\\) is \\\\(-11\\\\).', additional_kwargs={}, response_metadata={}),\n",
       "  HumanMessage(content='What is nine plus 10, minus 4 * 2 adn the result to the power of 3', additional_kwargs={}, response_metadata={}),\n",
       "  AIMessage(content='The result of \\\\( (9 + 10 - 4 \\\\times 2)^3 \\\\) is \\\\( 1331 \\\\).', additional_kwargs={}, response_metadata={})],\n",
       " 'output': 'The result of \\\\( (9 + 10 - 4 \\\\times 2)^3 \\\\) is \\\\( 1331 \\\\).'}"
      ]
     },
     "execution_count": 22,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "agent_executor.invoke({\n",
    "    \"input\": \"What is nine plus 10, minus 4 * 2 adn the result to the power of 3\",\n",
    "    \"chat_history\": memory\n",
    "})"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "id": "6c0ab1c6",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Ejecucion para validar respuesta: 1331\n"
     ]
    }
   ],
   "source": [
    "answ = (9+10-(4*2))**3\n",
    "\n",
    "print(f'Ejecucion para validar respuesta: {answ}')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "id": "0183ec19",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "\n",
      "\u001b[1m> Entering new AgentExecutor chain...\u001b[0m\n",
      "\u001b[32;1m\u001b[1;3mYour name is Bric.\u001b[0m\n",
      "\n",
      "\u001b[1m> Finished chain.\u001b[0m\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "{'input': 'What is my name',\n",
       " 'chat_history': [HumanMessage(content='what is 10.7 multiplied by 7.68?', additional_kwargs={}, response_metadata={}),\n",
       "  AIMessage(content='10.7 multiplied by 7.68 is approximately 82.18.', additional_kwargs={}, response_metadata={}),\n",
       "  HumanMessage(content='what is 10.7 multiplied by 7.68?', additional_kwargs={}, response_metadata={}),\n",
       "  AIMessage(content='10.7 multiplied by 7.68 is approximately 82.18.', additional_kwargs={}, response_metadata={}),\n",
       "  HumanMessage(content='what is 10.7 multiplied by 7.68?', additional_kwargs={}, response_metadata={}),\n",
       "  AIMessage(content='10.7 multiplied by 7.68 is approximately 82.18.', additional_kwargs={}, response_metadata={}),\n",
       "  HumanMessage(content='My name is bric', additional_kwargs={}, response_metadata={}),\n",
       "  AIMessage(content='Nice to meet you, Bric! How can I assist you today?', additional_kwargs={}, response_metadata={}),\n",
       "  HumanMessage(content='What is nine plus 10, minus 4 * 2, to the power of 3', additional_kwargs={}, response_metadata={}),\n",
       "  AIMessage(content='The result of \\\\( 9 + 10 - 4 \\\\times 2^3 \\\\) is \\\\(-11\\\\).', additional_kwargs={}, response_metadata={}),\n",
       "  HumanMessage(content='What is nine plus 10, minus 4 * 2 adn the result to the power of 3', additional_kwargs={}, response_metadata={}),\n",
       "  AIMessage(content='The result of \\\\( (9 + 10 - 4 \\\\times 2)^3 \\\\) is \\\\( 1331 \\\\).', additional_kwargs={}, response_metadata={}),\n",
       "  HumanMessage(content='What is my name', additional_kwargs={}, response_metadata={}),\n",
       "  AIMessage(content='Your name is Bric.', additional_kwargs={}, response_metadata={})],\n",
       " 'output': 'Your name is Bric.'}"
      ]
     },
     "execution_count": 26,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "agent_executor.invoke({\n",
    "    \"input\": \"What is my name\",\n",
    "    \"chat_history\": memory\n",
    "})"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "c05f5b6c",
   "metadata": {},
   "source": [
    "### 2.2 Web search with SerpAPI"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "a4295c51",
   "metadata": {},
   "source": [
    "En este ejemplo, utilizaremos la misma configuración de agente y ejecutor que antes, pero añadiremos el servicio SerpAPI para permitir que nuestro agente busque información en la web.\n",
    "\n",
    "Para usar esta herramienta, necesitas una clave API. Con el plan gratuito, puedes realizar hasta 100 búsquedas por mes.\n",
    "\n",
    "https://serpapi.com/"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "id": "39a79afd",
   "metadata": {},
   "outputs": [],
   "source": [
    "os.environ[\"SERPAPI_API_KEY\"] = os.getenv(\"SERPAPI_API_KEY\") \\\n",
    "    or getpass(\"Enter your SerpAPI API key: \")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "id": "eaffaa99",
   "metadata": {},
   "outputs": [],
   "source": [
    "from langchain.agents import load_tools\n",
    "\n",
    "toolbox = load_tools(tool_names=['serpapi'], llm=llm)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "7c619e55",
   "metadata": {},
   "source": [
    "Estas herramientas personalizadas pueden revisar tu dirección IP para averiguar dónde te encuentras actualmente. Luego, utilizaremos una función secundaria para obtener la fecha y hora actual, y usaremos esta información para ingresarla en SerpAPI y así encontrar el patrón climático en tu zona y en el momento en que se ejecuta la función."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "id": "36078c12",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "\n",
      "\u001b[1m> Entering new AgentExecutor chain...\u001b[0m\n",
      "\u001b[32;1m\u001b[1;3m\n",
      "Invoking: `get_current_datetime` with `{}`\n",
      "\n",
      "\n",
      "\u001b[0m\u001b[33;1m\u001b[1;3m2025-05-18 18:04:48\u001b[0m\u001b[32;1m\u001b[1;3m\n",
      "Invoking: `get_location_from_ip` with `{}`\n",
      "\n",
      "\n",
      "\u001b[0m\u001b[38;5;200m\u001b[1;3mLatitude: 4.6097,\n",
      "Longitude: -74.0817,\n",
      "City: Bogotá,\n",
      "Country: CO\u001b[0m\u001b[32;1m\u001b[1;3m\n",
      "Invoking: `Search` with `current weather in Bogotá, Colombia`\n",
      "\n",
      "\n",
      "\u001b[0m\u001b[36;1m\u001b[1;3m{'type': 'weather_result', 'temperature': '56', 'unit': 'Fahrenheit', 'precipitation': '65%', 'humidity': '99%', 'wind': '2 mph', 'location': 'Bogotá, Bogota, Colombia', 'date': 'Sunday 6:00 PM', 'weather': 'Light rain'}\u001b[0m\u001b[32;1m\u001b[1;3mThe current date and time is **May 18, 2025, 18:04:48**. \n",
      "\n",
      "The weather in **Bogotá, Colombia** is **light rain** with a temperature of **13°C** (which is approximately 56°F). The humidity is at **99%** with a wind speed of **2 mph**.\u001b[0m\n",
      "\n",
      "\u001b[1m> Finished chain.\u001b[0m\n"
     ]
    }
   ],
   "source": [
    "import requests\n",
    "from datetime import datetime\n",
    "\n",
    "# Crear Herramienta que permite obtener la IP para identificar la ubicacion regional\n",
    "\n",
    "@tool\n",
    "def get_location_from_ip():\n",
    "    \"\"\"Get the geographical location based on the IP address.\"\"\"\n",
    "    try:\n",
    "        response = requests.get(\"https://ipinfo.io/json\")\n",
    "        data = response.json()\n",
    "        if 'loc' in data:\n",
    "            latitude, longitude = data['loc'].split(',')\n",
    "            data = (\n",
    "                f\"Latitude: {latitude},\\n\"\n",
    "                f\"Longitude: {longitude},\\n\"\n",
    "                f\"City: {data.get('city', 'N/A')},\\n\"\n",
    "                f\"Country: {data.get('country', 'N/A')}\"\n",
    "            )\n",
    "            return data\n",
    "        else:\n",
    "            return \"Location could not be determined.\"\n",
    "    except Exception as e:\n",
    "        return f\"Error occurred: {e}\"\n",
    "\n",
    "@tool\n",
    "def get_current_datetime() -> str:\n",
    "    \"\"\"Return the current date and time.\"\"\"\n",
    "    return datetime.now().strftime(\"%Y-%m-%d %H:%M:%S\")\n",
    "\n",
    "\n",
    "# Crear Template del prompt\n",
    "\n",
    "prompt = ChatPromptTemplate.from_messages([\n",
    "    (\"system\", \"you're a helpful assistant\"),\n",
    "    (\"human\", \"{input}\"),\n",
    "    (\"placeholder\", \"{agent_scratchpad}\")\n",
    "])\n",
    "\n",
    "# Crear Agente\n",
    "\n",
    "tools = toolbox + [get_current_datetime, get_location_from_ip]\n",
    "\n",
    "agent = create_tool_calling_agent(\n",
    "    llm=llm, tools=tools, prompt=prompt\n",
    ")\n",
    "\n",
    "agent_executor = AgentExecutor(\n",
    "    agent=agent, tools=tools, verbose=True\n",
    ")\n",
    "\n",
    "# Invocar Respuesta\n",
    "\n",
    "out = agent_executor.invoke({\n",
    "    \"input\": (\n",
    "        \"I have a few questions, what is the date and time right now? \"\n",
    "        \"How is the weather where I am? Please give me degrees in Celsius\"\n",
    "    )\n",
    "})"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "id": "8b9a65af",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/markdown": [
       "The current date and time is **May 18, 2025, 18:04:48**. \n",
       "\n",
       "The weather in **Bogotá, Colombia** is **light rain** with a temperature of **13°C** (which is approximately 56°F). The humidity is at **99%** with a wind speed of **2 mph**."
      ],
      "text/plain": [
       "<IPython.core.display.Markdown object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "from IPython.display import display, Markdown\n",
    "\n",
    "display(Markdown(out[\"output\"]))"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "db338c04",
   "metadata": {},
   "source": [
    "## 3. Agente Ejecutador"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "6448034b",
   "metadata": {},
   "source": [
    "Cuando hablamos de agentes, una parte importante de un \"agente\" es simplemente lógica de código, que ejecuta iterativamente llamadas al LLM y procesa sus salidas. La lógica exacta varía considerablemente, pero un ejemplo bien conocido es el agente ReAct.\n",
    "\n",
    "![ReAct process](https://www.aurelio.ai/_next/image?url=%2Fimages%2Fposts%2Fai-agents%2Fai-agents-00.png&w=640&q=75)\n",
    "\n",
    "Los agentes Reason + Action (ReAct) utilizan pasos iterativos de razonamiento y acción para incorporar el pensamiento en cadena (chain-of-thought) y el uso de herramientas en su ejecución. Durante el paso de razonamiento, el LLM genera los pasos a seguir para responder a la consulta. Luego, el LLM genera la entrada de acción, que nuestra lógica de código interpreta como una llamada a una herramienta.\n",
    "\n",
    "![Agentic graph of ReAct](https://www.aurelio.ai/_next/image?url=%2Fimages%2Fposts%2Fai-agents%2Fai-agents-01.png&w=640&q=75)\n",
    "\n",
    "Después del paso de acción, obtenemos una observación como resultado de la llamada a la herramienta. Luego, alimentamos esa observación nuevamente a la lógica del ejecutor del agente para obtener una respuesta final o continuar con más pasos de razonamiento y acción.\n",
    "\n",
    "El agente y el ejecutor de agente que construiremos seguirán este patrón."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "id": "657a25c4",
   "metadata": {},
   "outputs": [],
   "source": [
    "from langchain_core.prompts import ChatPromptTemplate, MessagesPlaceholder\n",
    "\n",
    "prompt = ChatPromptTemplate.from_messages([\n",
    "    (\"system\", (\n",
    "        \"You're a helpful assistant. When answering a user's question \"\n",
    "        \"you should first use one of the tools provided. After using a \"\n",
    "        \"tool the tool output will be provided in the \"\n",
    "        \"'scratchpad' below. If you have an answer in the \"\n",
    "        \"scratchpad you should not use any more tools and \"\n",
    "        \"instead answer directly to the user.\"\n",
    "    )),\n",
    "    MessagesPlaceholder(variable_name=\"chat_history\"),\n",
    "    (\"human\", \"{input}\"),\n",
    "    MessagesPlaceholder(variable_name=\"agent_scratchpad\"),\n",
    "])"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "3324f6b3",
   "metadata": {},
   "source": [
    "Para añadir herramientas a nuestro LLM, utilizaremos el método bind_tools dentro del constructor de LCEL, el cual tomará nuestras herramientas y las añadirá al LLM. También incluiremos el argumento tool_choice=\"any\" en bind_tools, lo cual indica al LLM que DEBE usar una herramienta, es decir, no puede proporcionar una respuesta final directamente (y por lo tanto, no usar una herramienta).\n",
    "\n",
    "Debido a que configuramos tool_choice=\"any\" para forzar el uso de una herramienta, el campo habitual content estará vacío, ya que ese campo se utiliza para la salida en lenguaje natural, es decir, la respuesta final del LLM. Para encontrar la salida de la herramienta, necesitamos observar el campo tool_calls."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "id": "041eccb4",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "AIMessage(content='', additional_kwargs={'tool_calls': [{'id': 'call_r1hIi0hJqhLz2zfzYhDxxcw6', 'function': {'arguments': '{\"x\":10,\"y\":10}', 'name': 'add'}, 'type': 'function'}], 'refusal': None}, response_metadata={'token_usage': {'completion_tokens': 17, 'prompt_tokens': 197, 'total_tokens': 214, 'completion_tokens_details': {'accepted_prediction_tokens': 0, 'audio_tokens': 0, 'reasoning_tokens': 0, 'rejected_prediction_tokens': 0}, 'prompt_tokens_details': {'audio_tokens': 0, 'cached_tokens': 0}}, 'model_name': 'gpt-4o-mini-2024-07-18', 'system_fingerprint': 'fp_dbaca60df0', 'finish_reason': 'tool_calls', 'logprobs': None}, id='run-0a58f971-8ef3-4a15-b8b9-31ecf4f03cd1-0', tool_calls=[{'name': 'add', 'args': {'x': 10, 'y': 10}, 'id': 'call_r1hIi0hJqhLz2zfzYhDxxcw6', 'type': 'tool_call'}], usage_metadata={'input_tokens': 197, 'output_tokens': 17, 'total_tokens': 214, 'input_token_details': {'audio': 0, 'cache_read': 0}, 'output_token_details': {'audio': 0, 'reasoning': 0}})"
      ]
     },
     "execution_count": 33,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "from langchain_core.runnables.base import RunnableSerializable\n",
    "\n",
    "tools = [add, subtract, multiply, exponentiate]\n",
    "\n",
    "# define the agent runnable\n",
    "agent: RunnableSerializable = (\n",
    "    {\n",
    "        \"input\": lambda x: x[\"input\"],\n",
    "        \"chat_history\": lambda x: x[\"chat_history\"],\n",
    "        \"agent_scratchpad\": lambda x: x.get(\"agent_scratchpad\", [])\n",
    "    }\n",
    "    | prompt\n",
    "    | llm.bind_tools(tools, tool_choice=\"any\")\n",
    ")\n",
    "\n",
    "tool_call = agent.invoke({\"input\": \"What is 10 + 10\", \"chat_history\": []})\n",
    "tool_call"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "id": "1cdcf9ae",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[{'name': 'add',\n",
       "  'args': {'x': 10, 'y': 10},\n",
       "  'id': 'call_r1hIi0hJqhLz2zfzYhDxxcw6',\n",
       "  'type': 'tool_call'}]"
      ]
     },
     "execution_count": 34,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "tool_call.tool_calls"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 35,
   "id": "71d85f52",
   "metadata": {},
   "outputs": [],
   "source": [
    "# create tool name to function mapping\n",
    "name2tool = {tool.name: tool.func for tool in tools}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 37,
   "id": "4e072108",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "20"
      ]
     },
     "execution_count": 37,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "tool_exec_content = name2tool[tool_call.tool_calls[0][\"name\"]](\n",
    "    **tool_call.tool_calls[0][\"args\"]\n",
    ")\n",
    "tool_exec_content"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 38,
   "id": "362b99f2",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "AIMessage(content='', additional_kwargs={'tool_calls': [{'id': 'call_8t9bYgAHEPVNJaGqzVwWlVMf', 'function': {'arguments': '{\"x\":10,\"y\":10}', 'name': 'add'}, 'type': 'function'}], 'refusal': None}, response_metadata={'token_usage': {'completion_tokens': 17, 'prompt_tokens': 227, 'total_tokens': 244, 'completion_tokens_details': {'accepted_prediction_tokens': 0, 'audio_tokens': 0, 'reasoning_tokens': 0, 'rejected_prediction_tokens': 0}, 'prompt_tokens_details': {'audio_tokens': 0, 'cached_tokens': 0}}, 'model_name': 'gpt-4o-mini-2024-07-18', 'system_fingerprint': 'fp_dbaca60df0', 'finish_reason': 'tool_calls', 'logprobs': None}, id='run-806e054b-3f78-476b-90f6-2589ef79fa8c-0', tool_calls=[{'name': 'add', 'args': {'x': 10, 'y': 10}, 'id': 'call_8t9bYgAHEPVNJaGqzVwWlVMf', 'type': 'tool_call'}], usage_metadata={'input_tokens': 227, 'output_tokens': 17, 'total_tokens': 244, 'input_token_details': {'audio': 0, 'cache_read': 0}, 'output_token_details': {'audio': 0, 'reasoning': 0}})"
      ]
     },
     "execution_count": 38,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "from langchain_core.messages import ToolMessage\n",
    "\n",
    "tool_exec = ToolMessage(\n",
    "    content=f\"The {tool_call.tool_calls[0]['name']} tool returned {tool_exec_content}\",\n",
    "    tool_call_id=tool_call.tool_calls[0][\"id\"]\n",
    ")\n",
    "\n",
    "out = agent.invoke({\n",
    "    \"input\": \"What is 10 + 10\",\n",
    "    \"chat_history\": [],\n",
    "    \"agent_scratchpad\": [tool_call, tool_exec]\n",
    "})\n",
    "out"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "326da571",
   "metadata": {},
   "source": [
    "A pesar de tener la respuesta en nuestro agent_scratchpad, el LLM sigue intentando usar la herramienta de nuevo. Este comportamiento ocurre porque vinculamos las herramientas al LLM con tool_choice=\"any\". Cuando configuramos tool_choice como \"any\" o \"required\", le indicamos al LLM que DEBE usar una herramienta, es decir, que no puede proporcionar una respuesta final directamente.\n",
    "\n",
    "Hay dos opciones para solucionar esto:\n",
    "\n",
    "Configurar tool_choice=\"auto\" para indicarle al LLM que puede elegir usar una herramienta o proporcionar una respuesta final.\n",
    "\n",
    "Crear una herramienta llamada final_answer — lo explicaremos en breve."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "6d4d6cd4",
   "metadata": {},
   "source": [
    "### 3.1 Agente Serializable"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "e5b43d71",
   "metadata": {},
   "source": [
    "RunnableSerializable es una interfaz o tipo en LangChain que representa un objeto ejecutable (runnable) que además puede ser serializado y deserializado fácilmente. Esto significa que:\n",
    "\n",
    "Runnable: Puede recibir una entrada, procesarla y devolver una salida (como una función o pipeline).\n",
    "\n",
    "Serializable: Puede guardarse en un formato persistente (por ejemplo, JSON, pickle o un formato propio) para almacenarlo, compartirlo o cargarlo después sin perder su funcionalidad.\n",
    "\n",
    "| Característica                     | Descripción                                                                                               |\n",
    "| ---------------------------------- | --------------------------------------------------------------------------------------------------------- |\n",
    "| **Ejecución modular**              | Puede ejecutarse con un método estándar (por ejemplo, `.invoke()`, `.run()` o similar).                   |\n",
    "| **Composición encadenada**         | Permite encadenar múltiples objetos `Runnable` para construir pipelines complejos fácilmente.             |\n",
    "| **Serialización/deserialización**  | Puede ser convertido a un formato portable y luego restaurado sin pérdida de estado o configuración.      |\n",
    "| **Interoperabilidad**              | Compatible con diferentes componentes de LangChain, como prompts, modelos de lenguaje, herramientas, etc. |\n",
    "| **Flexibilidad en entrada/salida** | Soporta entrada y salida en diferentes formatos (strings, diccionarios, listas, objetos).                 |\n",
    "| **Soporte para memoria**           | Puede integrarse con mecanismos de memoria para mantener contexto entre ejecuciones.                      |\n",
    "| **Configurabilidad**               | Puede aceptar configuraciones, como parámetros de LLM, herramientas, y opciones de control.               |\n",
    "\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 39,
   "id": "14250463",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[{'name': 'add',\n",
       "  'args': {'x': 10, 'y': 10},\n",
       "  'id': 'call_gQdDOqpIVFgqhEn59LXmzlEu',\n",
       "  'type': 'tool_call'}]"
      ]
     },
     "execution_count": 39,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "@tool\n",
    "def final_answer(answer: str, tools_used: list[str]) -> str:\n",
    "    \"\"\"Use this tool to provide a final answer to the user.\n",
    "    The answer should be in natural language as this will be provided\n",
    "    to the user directly. The tools_used must include a list of tool\n",
    "    names that were used within the `scratchpad`.\n",
    "    \"\"\"\n",
    "    return {\"answer\": answer, \"tools_used\": tools_used}\n",
    "\n",
    "tools = [final_answer, add, subtract, multiply, exponentiate]\n",
    "\n",
    "# we need to update our name2tool mapping too\n",
    "name2tool = {tool.name: tool.func for tool in tools}\n",
    "\n",
    "agent: RunnableSerializable = (\n",
    "    {\n",
    "        \"input\": lambda x: x[\"input\"],\n",
    "        \"chat_history\": lambda x: x[\"chat_history\"],\n",
    "        \"agent_scratchpad\": lambda x: x.get(\"agent_scratchpad\", [])\n",
    "    }\n",
    "    | prompt\n",
    "    | llm.bind_tools(tools, tool_choice=\"any\")  # we're forcing tool use again\n",
    ")\n",
    "\n",
    "tool_call = agent.invoke({\"input\": \"What is 10 + 10\", \"chat_history\": []})\n",
    "tool_call.tool_calls"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 40,
   "id": "e9e1f423",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "AIMessage(content='', additional_kwargs={'tool_calls': [{'id': 'call_Y5UPFPYUrvENFO3XsWPeK8zC', 'function': {'arguments': '{\"answer\":\"10 + 10 equals 20.\",\"tools_used\":[\"functions.add\"]}', 'name': 'final_answer'}, 'type': 'function'}], 'refusal': None}, response_metadata={'token_usage': {'completion_tokens': 27, 'prompt_tokens': 299, 'total_tokens': 326, 'completion_tokens_details': {'accepted_prediction_tokens': 0, 'audio_tokens': 0, 'reasoning_tokens': 0, 'rejected_prediction_tokens': 0}, 'prompt_tokens_details': {'audio_tokens': 0, 'cached_tokens': 0}}, 'model_name': 'gpt-4o-mini-2024-07-18', 'system_fingerprint': 'fp_dbaca60df0', 'finish_reason': 'tool_calls', 'logprobs': None}, id='run-ae975fb6-ec6f-4596-9b23-d9b92f3effdc-0', tool_calls=[{'name': 'final_answer', 'args': {'answer': '10 + 10 equals 20.', 'tools_used': ['functions.add']}, 'id': 'call_Y5UPFPYUrvENFO3XsWPeK8zC', 'type': 'tool_call'}], usage_metadata={'input_tokens': 299, 'output_tokens': 27, 'total_tokens': 326, 'input_token_details': {'audio': 0, 'cache_read': 0}, 'output_token_details': {'audio': 0, 'reasoning': 0}})"
      ]
     },
     "execution_count": 40,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "tool_out = name2tool[tool_call.tool_calls[0][\"name\"]](\n",
    "    **tool_call.tool_calls[0][\"args\"]\n",
    ")\n",
    "\n",
    "tool_exec = ToolMessage(\n",
    "    content=f\"The {tool_call.tool_calls[0]['name']} tool returned {tool_out}\",\n",
    "    tool_call_id=tool_call.tool_calls[0][\"id\"]\n",
    ")\n",
    "\n",
    "out = agent.invoke({\n",
    "    \"input\": \"What is 10 + 10\",\n",
    "    \"chat_history\": [],\n",
    "    \"agent_scratchpad\": [tool_call, tool_exec]\n",
    "})\n",
    "out"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 41,
   "id": "0cd42f53",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{'answer': '10 + 10 equals 20.', 'tools_used': ['functions.add']}"
      ]
     },
     "execution_count": 41,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "out.tool_calls[0][\"args\"]"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "979aed2b",
   "metadata": {},
   "source": [
    "### 3.2 Agent Execution Loop"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "5f4d1e5d",
   "metadata": {},
   "source": [
    "Agent\n",
    "Es la lógica o estrategia que define qué hacer.\n",
    "\n",
    "Contiene la definición de cómo se eligen las acciones, qué herramientas usar, y cómo procesar la información.\n",
    "\n",
    "Por ejemplo, un agent puede decidir llamar a una calculadora, hacer una búsqueda, o responder directamente.\n",
    "\n",
    "En esencia, el agent es la \"mente\" o el plan de acción.\n",
    "\n",
    "AgentExecutor\n",
    "Es el mecanismo o loop de ejecución que maneja cómo se lleva a cabo esa lógica.\n",
    "\n",
    "Controla las iteraciones entre la generación de acciones por parte del agent, la ejecución de herramientas (tools), la recepción de resultados, y la continuación del proceso.\n",
    "\n",
    "Se encarga de hacer que el agent pueda funcionar en un flujo continuo hasta llegar a una respuesta final.\n",
    "\n",
    "En otras palabras, el agent_executor es el \"motor\" que hace funcionar el agent.\n",
    "\n",
    "Resumiendo:\n",
    "El agent define la lógica de decisiones y acciones, mientras que el agent_executor es quien ejecuta esa lógica en un ciclo controlado hasta completar la tarea."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 42,
   "id": "23f15cf1",
   "metadata": {},
   "outputs": [],
   "source": [
    "from langchain_core.messages import BaseMessage, HumanMessage, AIMessage\n",
    "\n",
    "\n",
    "class CustomAgentExecutor:\n",
    "    chat_history: list[BaseMessage]\n",
    "\n",
    "    def __init__(self, max_iterations: int = 3):\n",
    "        self.chat_history = []\n",
    "        self.max_iterations = max_iterations\n",
    "        self.agent: RunnableSerializable = (\n",
    "            {\n",
    "                \"input\": lambda x: x[\"input\"],\n",
    "                \"chat_history\": lambda x: x[\"chat_history\"],\n",
    "                \"agent_scratchpad\": lambda x: x.get(\"agent_scratchpad\", [])\n",
    "            }\n",
    "            | prompt\n",
    "            | llm.bind_tools(tools, tool_choice=\"any\")  # we're forcing tool use again\n",
    "        )\n",
    "\n",
    "    def invoke(self, input: str) -> dict:\n",
    "        # invoke the agent but we do this iteratively in a loop until\n",
    "        # reaching a final answer\n",
    "        count = 0\n",
    "        agent_scratchpad = []\n",
    "        while count < self.max_iterations:\n",
    "            # invoke a step for the agent to generate a tool call\n",
    "            tool_call = self.agent.invoke({\n",
    "                \"input\": input,\n",
    "                \"chat_history\": self.chat_history,\n",
    "                \"agent_scratchpad\": agent_scratchpad\n",
    "            })\n",
    "            # add initial tool call to scratchpad\n",
    "            agent_scratchpad.append(tool_call)\n",
    "            # otherwise we execute the tool and add it's output to the agent scratchpad\n",
    "            tool_name = tool_call.tool_calls[0][\"name\"]\n",
    "            tool_args = tool_call.tool_calls[0][\"args\"]\n",
    "            tool_call_id = tool_call.tool_calls[0][\"id\"]\n",
    "            tool_out = name2tool[tool_name](**tool_args)\n",
    "            # add the tool output to the agent scratchpad\n",
    "            tool_exec = ToolMessage(\n",
    "                content=f\"{tool_out}\",\n",
    "                tool_call_id=tool_call_id\n",
    "            )\n",
    "            agent_scratchpad.append(tool_exec)\n",
    "            # add a print so we can see intermediate steps\n",
    "            print(f\"{count}: {tool_name}({tool_args})\")\n",
    "            count += 1\n",
    "            # if the tool call is the final answer tool, we stop\n",
    "            if tool_name == \"final_answer\":\n",
    "                break\n",
    "        # add the final output to the chat history\n",
    "        final_answer = tool_out[\"answer\"]\n",
    "        self.chat_history.extend([\n",
    "            HumanMessage(content=input),\n",
    "            AIMessage(content=final_answer)\n",
    "        ])\n",
    "        # return the final answer in dict form\n",
    "        return json.dumps(tool_out)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 43,
   "id": "d6e9f3c2",
   "metadata": {},
   "outputs": [],
   "source": [
    "agent_executor = CustomAgentExecutor()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 44,
   "id": "25c9daaa",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0: add({'x': 10, 'y': 10})\n",
      "1: final_answer({'answer': '10 + 10 equals 20.', 'tools_used': ['functions.add']})\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "'{\"answer\": \"10 + 10 equals 20.\", \"tools_used\": [\"functions.add\"]}'"
      ]
     },
     "execution_count": 44,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "agent_executor.invoke(input=\"What is 10 + 10\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "eb99d6e0",
   "metadata": {},
   "source": [
    "## 4. LCEL (Langchain Expression Language)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 45,
   "id": "1ad83b0c",
   "metadata": {},
   "outputs": [],
   "source": [
    "from langchain import PromptTemplate\n",
    "\n",
    "prompt_template = \"Give me a small report on {topic}\"\n",
    "\n",
    "prompt = PromptTemplate(\n",
    "    input_variables=[\"topic\"],\n",
    "    template=prompt_template\n",
    ")\n",
    "\n",
    "import os\n",
    "from getpass import getpass\n",
    "from langchain_openai import ChatOpenAI\n",
    "\n",
    "os.environ[\"OPENAI_API_KEY\"] = os.getenv(\"OPENAI_API_KEY\") \\\n",
    "    or getpass(\"Enter your OpenAI API key: \")\n",
    "\n",
    "llm = ChatOpenAI(\n",
    "    model_name=\"gpt-4o-mini\",\n",
    "    temperature=0.0,\n",
    ")\n",
    "\n",
    "from langchain.schema.output_parser import StrOutputParser\n",
    "\n",
    "output_parser = StrOutputParser()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 46,
   "id": "dba0b959",
   "metadata": {},
   "outputs": [],
   "source": [
    "lcel_chain = prompt | llm | output_parser"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 47,
   "id": "2cf73dee",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'### Report on Retrieval-Augmented Generation (RAG)\\n\\n#### Introduction\\nRetrieval-Augmented Generation (RAG) is an innovative approach that combines the strengths of information retrieval and natural language generation. This method enhances the capabilities of language models by allowing them to access external knowledge bases or documents during the generation process, thereby improving the relevance and accuracy of the generated content.\\n\\n#### Key Concepts\\n1. **Retrieval Mechanism**: RAG employs a retrieval system to fetch relevant documents or pieces of information from a large corpus based on the input query. This is typically done using techniques such as vector embeddings or traditional keyword-based search.\\n\\n2. **Generation Mechanism**: After retrieving relevant information, a generative model (often based on architectures like Transformers) synthesizes this information into coherent and contextually appropriate responses. The generative model can be fine-tuned to ensure that the output aligns with the desired style and tone.\\n\\n3. **Hybrid Approach**: By integrating retrieval and generation, RAG leverages the vast amount of information available in external databases while maintaining the fluency and creativity of generative models. This hybrid approach allows for more informed and contextually rich outputs.\\n\\n#### Applications\\n- **Question Answering**: RAG is particularly effective in question-answering systems where users seek specific information. By retrieving relevant documents, the model can provide accurate answers backed by credible sources.\\n- **Content Creation**: In content generation tasks, RAG can pull in facts, statistics, or quotes from external sources, enriching the generated text and making it more informative.\\n- **Conversational Agents**: RAG can enhance chatbots and virtual assistants by allowing them to access up-to-date information, improving their ability to handle diverse queries.\\n\\n#### Advantages\\n- **Improved Accuracy**: By grounding responses in retrieved information, RAG reduces the likelihood of generating incorrect or misleading content.\\n- **Dynamic Knowledge**: RAG can adapt to new information without the need for retraining the entire model, as it can access updated external databases.\\n- **Contextual Relevance**: The retrieval process ensures that the generated content is relevant to the specific context of the query.\\n\\n#### Challenges\\n- **Latency**: The retrieval process can introduce latency, which may affect the responsiveness of applications, especially in real-time systems.\\n- **Quality of Retrieved Information**: The effectiveness of RAG heavily depends on the quality and relevance of the retrieved documents. Poor retrieval can lead to suboptimal generation.\\n- **Complexity**: Implementing a RAG system requires expertise in both retrieval and generation techniques, making it more complex than traditional models.\\n\\n#### Conclusion\\nRetrieval-Augmented Generation represents a significant advancement in the field of natural language processing, merging the capabilities of information retrieval with generative models. Its ability to produce accurate, contextually relevant, and informative content makes it a valuable tool across various applications, from customer support to content creation. As research and development in this area continue, RAG is poised to play a crucial role in the evolution of intelligent systems that require both knowledge and creativity.'"
      ]
     },
     "execution_count": 47,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "result = lcel_chain.invoke(\"retrieval augmented generation\")\n",
    "result "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 48,
   "id": "3f58c82d",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/markdown": [
       "### Report on Retrieval-Augmented Generation (RAG)\n",
       "\n",
       "#### Introduction\n",
       "Retrieval-Augmented Generation (RAG) is an innovative approach that combines the strengths of information retrieval and natural language generation. This method enhances the capabilities of language models by allowing them to access external knowledge bases or documents during the generation process, thereby improving the relevance and accuracy of the generated content.\n",
       "\n",
       "#### Key Concepts\n",
       "1. **Retrieval Mechanism**: RAG employs a retrieval system to fetch relevant documents or pieces of information from a large corpus based on the input query. This is typically done using techniques such as vector embeddings or traditional keyword-based search.\n",
       "\n",
       "2. **Generation Mechanism**: After retrieving relevant information, a generative model (often based on architectures like Transformers) synthesizes this information into coherent and contextually appropriate responses. The generative model can be fine-tuned to ensure that the output aligns with the desired style and tone.\n",
       "\n",
       "3. **Hybrid Approach**: By integrating retrieval and generation, RAG leverages the vast amount of information available in external databases while maintaining the fluency and creativity of generative models. This hybrid approach allows for more informed and contextually rich outputs.\n",
       "\n",
       "#### Applications\n",
       "- **Question Answering**: RAG is particularly effective in question-answering systems where users seek specific information. By retrieving relevant documents, the model can provide accurate answers backed by credible sources.\n",
       "- **Content Creation**: In content generation tasks, RAG can pull in facts, statistics, or quotes from external sources, enriching the generated text and making it more informative.\n",
       "- **Conversational Agents**: RAG can enhance chatbots and virtual assistants by allowing them to access up-to-date information, improving their ability to handle diverse queries.\n",
       "\n",
       "#### Advantages\n",
       "- **Improved Accuracy**: By grounding responses in retrieved information, RAG reduces the likelihood of generating incorrect or misleading content.\n",
       "- **Dynamic Knowledge**: RAG can adapt to new information without the need for retraining the entire model, as it can access updated external databases.\n",
       "- **Contextual Relevance**: The retrieval process ensures that the generated content is relevant to the specific context of the query.\n",
       "\n",
       "#### Challenges\n",
       "- **Latency**: The retrieval process can introduce latency, which may affect the responsiveness of applications, especially in real-time systems.\n",
       "- **Quality of Retrieved Information**: The effectiveness of RAG heavily depends on the quality and relevance of the retrieved documents. Poor retrieval can lead to suboptimal generation.\n",
       "- **Complexity**: Implementing a RAG system requires expertise in both retrieval and generation techniques, making it more complex than traditional models.\n",
       "\n",
       "#### Conclusion\n",
       "Retrieval-Augmented Generation represents a significant advancement in the field of natural language processing, merging the capabilities of information retrieval with generative models. Its ability to produce accurate, contextually relevant, and informative content makes it a valuable tool across various applications, from customer support to content creation. As research and development in this area continue, RAG is poised to play a crucial role in the evolution of intelligent systems that require both knowledge and creativity."
      ],
      "text/plain": [
       "<IPython.core.display.Markdown object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "display(Markdown(result))"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "a2b15559",
   "metadata": {},
   "source": [
    "### 4.1 Como funciona el operador Pipe?"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "2ad6f542",
   "metadata": {},
   "source": [
    "Antes de pasar a otras funcionalidades de LCEL, tomemos un momento para entender qué hace el operador pipe | y cómo funciona.\n",
    "\n",
    "Desde el punto de vista funcional, el operador pipe indica que todo lo que se produzca en el lado izquierdo se pasará como entrada al lado derecho. En el ejemplo prompt | llm | output_parser, vemos que prompt se pasa como entrada a llm, y luego su salida se pasa a output_parser.\n",
    "\n",
    "El operador pipe es una forma de encadenar componentes, y expresa que la salida del lado izquierdo será la entrada del lado derecho.\n",
    "\n",
    "Vamos a crear una clase básica llamada Runnable que transformará una función proporcionada en una clase ejecutable, que luego podremos usar con el operador pipe |.\n",
    "\n",
    "Con la clase Runnable, podremos envolver una función dentro de la clase, lo que nos permitirá luego encadenar múltiples de estas funciones ejecutables utilizando el método __or__.\n",
    "\n",
    "Primero, vamos a crear algunas funciones que encadenaremos:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 49,
   "id": "9b10fe7f",
   "metadata": {},
   "outputs": [],
   "source": [
    "class Runnable:\n",
    "    def __init__(self, func):\n",
    "        self.func = func\n",
    "    def __or__(self, other):\n",
    "        def chained_func(*args, **kwargs):\n",
    "            return other.invoke(self.func(*args, **kwargs))\n",
    "        return Runnable(chained_func)\n",
    "    def invoke(self, *args, **kwargs):\n",
    "        return self.func(*args, **kwargs)\n",
    "\n",
    "def add_five(x):\n",
    "    return x+5\n",
    "\n",
    "def sub_five(x):\n",
    "    return x-5\n",
    "\n",
    "def mul_five(x):\n",
    "    return x*5\n",
    "\n",
    "add_five_runnable = Runnable(add_five)\n",
    "sub_five_runnable = Runnable(sub_five)\n",
    "mul_five_runnable = Runnable(mul_five)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 50,
   "id": "739f5aac",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "15"
      ]
     },
     "execution_count": 50,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "chain = (add_five_runnable).__or__(sub_five_runnable).__or__(mul_five_runnable)\n",
    "\n",
    "chain.invoke(3)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 51,
   "id": "756c31f0",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "15"
      ]
     },
     "execution_count": 51,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "chain = add_five_runnable | sub_five_runnable | mul_five_runnable\n",
    "\n",
    "chain.invoke(3)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "a60d0dfc",
   "metadata": {},
   "source": [
    "### 4.2 LCEL `RunnableLambda`\n",
    "\n",
    "La clase RunnableLambda es el método incorporado de LangChain para construir un objeto runnable (ejecutable) a partir de una función. Es decir, hace lo mismo que la clase personalizada Runnable que creamos anteriormente. Vamos a probarla con las mismas funciones que antes."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 52,
   "id": "3c387303",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "15"
      ]
     },
     "execution_count": 52,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "from langchain_core.runnables import RunnableLambda\n",
    "\n",
    "add_five_runnable = RunnableLambda(add_five)\n",
    "sub_five_runnable = RunnableLambda(sub_five)\n",
    "mul_five_runnable = RunnableLambda(mul_five)\n",
    "\n",
    "chain = add_five_runnable | sub_five_runnable | mul_five_runnable\n",
    "\n",
    "chain.invoke(3)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 53,
   "id": "9af87083",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/markdown": [
       "### Report on Artificial Intelligence (AI)\n",
       "\n",
       "#### Introduction\n",
       "Artificial Intelligence (AI) refers to the simulation of human intelligence in machines programmed to think and learn like humans. It encompasses a variety of technologies and methodologies, including machine learning, natural language processing, robotics, and computer vision. AI has rapidly evolved over the past few decades, becoming an integral part of various industries and daily life.\n",
       "\n",
       "#### Current State of AI\n",
       "As of 2023, AI technologies are being utilized across multiple sectors, including healthcare, finance, transportation, and entertainment. Key advancements include:\n",
       "\n",
       "1. **Machine Learning (ML)**: Algorithms that enable computers to learn from and make predictions based on data. Deep learning, a subset of ML, has led to breakthroughs in image and speech recognition.\n",
       "\n",
       "2. **Natural Language Processing (NLP)**: Technologies that allow machines to understand and respond to human language. Applications include chatbots, virtual assistants, and language translation services.\n",
       "\n",
       "3. **Computer Vision**: The ability of machines to interpret and make decisions based on visual data. This technology is widely used in facial recognition, autonomous vehicles, and medical imaging.\n",
       "\n",
       "4. **Robotics**: AI-driven robots are increasingly used in manufacturing, logistics, and even healthcare, performing tasks ranging from assembly line work to surgical assistance.\n",
       "\n",
       "#### Applications of AI\n",
       "- **Healthcare**: AI is used for diagnostics, personalized medicine, and predictive analytics, improving patient outcomes and operational efficiency.\n",
       "- **Finance**: AI algorithms analyze market trends, detect fraud, and automate trading, enhancing decision-making and risk management.\n",
       "- **Transportation**: Autonomous vehicles leverage AI for navigation and safety, while AI systems optimize traffic management and logistics.\n",
       "- **Entertainment**: Streaming services use AI to recommend content based on user preferences, while video games employ AI for more realistic and adaptive gameplay.\n",
       "\n",
       "#### Challenges and Ethical Considerations\n",
       "Despite its potential, AI poses several challenges:\n",
       "- **Bias and Fairness**: AI systems can perpetuate existing biases present in training data, leading to unfair outcomes.\n",
       "- **Privacy Concerns**: The use of AI in data collection raises significant privacy issues, necessitating robust regulations.\n",
       "- **Job Displacement**: Automation driven by AI may lead to job losses in certain sectors, prompting discussions about workforce retraining and economic impact.\n",
       "- **Security Risks**: AI technologies can be exploited for malicious purposes, including cyberattacks and misinformation campaigns.\n",
       "\n",
       "#### Future Outlook\n",
       "The future of AI is promising, with ongoing research aimed at creating more advanced, ethical, and transparent AI systems. Innovations in explainable AI (XAI) seek to make AI decision-making processes more understandable to users. Additionally, interdisciplinary collaboration will be crucial in addressing the ethical implications and societal impacts of AI.\n",
       "\n",
       "#### Conclusion\n",
       "AI is transforming industries and reshaping the way we live and work. While it offers significant benefits, it also presents challenges that require careful consideration and proactive management. As AI continues to evolve, its integration into society will necessitate a balanced approach that maximizes its potential while minimizing risks.\n",
       "\n",
       "---\n",
       "\n",
       "This report provides a brief overview of the current landscape of AI, its applications, challenges, and future directions."
      ],
      "text/plain": [
       "<IPython.core.display.Markdown object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "prompt_str = \"give me a small report about {topic}\"\n",
    "prompt = PromptTemplate(\n",
    "    input_variables=[\"topic\"],\n",
    "    template=prompt_str\n",
    ")\n",
    "\n",
    "chain = prompt | llm | output_parser\n",
    "\n",
    "result = chain.invoke(\"AI\")\n",
    "display(Markdown(result))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 54,
   "id": "f1abf84d",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/markdown": [
       "#### Introduction\n",
       "Retrieval-Augmented Generation (RAG) is an innovative approach that combines the strengths of information retrieval and natural language generation. This method enhances the capabilities of language models by allowing them to access external knowledge sources, thereby improving the accuracy and relevance of generated responses.\n",
       "#### Concept Overview\n",
       "RAG operates on the principle of integrating a retrieval mechanism with a generative model. The process typically involves two main components:\n",
       "1. **Retrieval Component**: This part of the system retrieves relevant documents or pieces of information from a large corpus based on a given query. It utilizes techniques such as vector embeddings and similarity search to identify the most pertinent data.\n",
       "2. **Generation Component**: After retrieving the relevant information, the generative model (often based on architectures like Transformers) synthesizes a coherent and contextually appropriate response. This model leverages the retrieved data to enhance its output, ensuring that the generated text is not only fluent but also factually grounded.\n",
       "#### Advantages\n",
       "- **Enhanced Knowledge Access**: By incorporating external knowledge, RAG can provide more accurate and contextually relevant information than standalone generative models.\n",
       "- **Dynamic Updates**: The retrieval component allows the system to access up-to-date information, making it adaptable to new data without the need for retraining the entire model.\n",
       "- **Improved Contextuality**: RAG can generate responses that are more aligned with user queries, as it bases its output on specific, relevant information retrieved in real-time.\n",
       "#### Applications\n",
       "RAG has a wide range of applications, including:\n",
       "- **Question Answering**: Providing precise answers to user queries by retrieving relevant documents and generating responses based on them.\n",
       "- **Chatbots and Virtual Assistants**: Enhancing conversational agents with the ability to pull in real-time information, making interactions more informative and engaging.\n",
       "- **Content Creation**: Assisting writers and content creators by providing relevant data and context, thereby improving the quality of generated content.\n",
       "#### Challenges\n",
       "Despite its advantages, RAG faces several challenges:\n",
       "- **Retrieval Quality**: The effectiveness of the system heavily relies on the quality of the retrieval component. Poor retrieval can lead to irrelevant or incorrect information being used in generation.\n",
       "- **Complexity**: Integrating retrieval and generation components can increase the complexity of the system, requiring careful tuning and optimization.\n",
       "- **Latency**: The retrieval process can introduce latency, which may affect the responsiveness of applications, particularly in real-time scenarios.\n",
       "#### Conclusion\n",
       "Retrieval-Augmented Generation represents a significant advancement in the field of natural language processing. By effectively combining retrieval and generation, RAG systems can produce more accurate, relevant, and contextually aware outputs. As research and development in this area continue to evolve, RAG is poised to play a crucial role in enhancing various applications, from conversational agents to content generation tools. Future work will likely focus on improving retrieval mechanisms, reducing latency, and addressing the challenges associated with integrating these two components."
      ],
      "text/plain": [
       "<IPython.core.display.Markdown object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "# Ejemplo adicionando tareas (Se reemplazan palabras)\n",
    "\n",
    "def extract_fact(x):\n",
    "    if \"\\n\\n\" in x:\n",
    "        return \"\\n\".join(x.split(\"\\n\\n\")[1:])\n",
    "    else:\n",
    "        return x\n",
    "\n",
    "old_word = \"AI\"\n",
    "new_word = \"skynet\"\n",
    "\n",
    "def replace_word(x):\n",
    "    return x.replace(old_word, new_word)\n",
    "\n",
    "\n",
    "extract_fact_runnable = RunnableLambda(extract_fact)\n",
    "replace_word_runnable = RunnableLambda(replace_word)\n",
    "\n",
    "chain = prompt | llm | output_parser | extract_fact_runnable | replace_word_runnable\n",
    "\n",
    "result = chain.invoke(\"retrieval augmented generation\")\n",
    "display(Markdown(result))"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "97f9486d",
   "metadata": {},
   "source": [
    "### 4.3 LCEL `RunnableParallel` and `RunnablePassthrough`"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "6c10f1d1",
   "metadata": {},
   "source": [
    "LCEL nos proporciona varias clases Runnable que nos permiten controlar el flujo de datos y el orden de ejecución a través de nuestras cadenas. Dos de estas son RunnableParallel y RunnablePassthrough.\n",
    "\n",
    "RunnableParallel — nos permite ejecutar múltiples instancias de Runnable en paralelo, actuando casi como una bifurcación en Y dentro de la cadena.\n",
    "\n",
    "RunnablePassthrough — nos permite pasar una variable a la siguiente Runnable sin modificarla."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 55,
   "id": "c942f179",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\Sebastian\\AppData\\Local\\Temp\\ipykernel_24476\\3699332964.py:4: LangChainDeprecationWarning: The class `OpenAIEmbeddings` was deprecated in LangChain 0.0.9 and will be removed in 1.0. An updated version of the class exists in the :class:`~langchain-openai package and should be used instead. To use it run `pip install -U :class:`~langchain-openai` and import as `from :class:`~langchain_openai import OpenAIEmbeddings``.\n",
      "  embedding = OpenAIEmbeddings()\n",
      "c:\\Users\\Sebastian\\Documents\\Projects\\Credibanco\\Modulo3\\.venv\\Lib\\site-packages\\docarray\\helper.py:224: SyntaxWarning: invalid escape sequence '\\*'\n",
      "  \"\"\"\n",
      "c:\\Users\\Sebastian\\Documents\\Projects\\Credibanco\\Modulo3\\.venv\\Lib\\site-packages\\pydantic\\_migration.py:283: UserWarning: `pydantic.error_wrappers:ValidationError` has been moved to `pydantic:ValidationError`.\n",
      "  warnings.warn(f'`{import_path}` has been moved to `{new_location}`.')\n"
     ]
    }
   ],
   "source": [
    "from langchain.embeddings import OpenAIEmbeddings\n",
    "from langchain.vectorstores import DocArrayInMemorySearch\n",
    "\n",
    "embedding = OpenAIEmbeddings()\n",
    "\n",
    "vecstore_a = DocArrayInMemorySearch.from_texts(\n",
    "    [\n",
    "        \"half the info is here\",\n",
    "        \"DeepSeek-V3 was released in December 2024\"\n",
    "    ],\n",
    "    embedding=embedding\n",
    ")\n",
    "vecstore_b = DocArrayInMemorySearch.from_texts(\n",
    "    [\n",
    "        \"the other half of the info is here\",\n",
    "        \"the DeepSeek-V3 LLM is a mixture of experts model with 671B parameters\"\n",
    "    ],\n",
    "    embedding=embedding\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 56,
   "id": "41ca250e",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Here you can see the prompt does have three inputs, two for context and one for the question itself.\n",
    "\n",
    "prompt_str = \"\"\"Using the context provided, answer the user's question.\n",
    "Context:\n",
    "{context_a}\n",
    "{context_b}\n",
    "\"\"\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 57,
   "id": "310edebb",
   "metadata": {},
   "outputs": [],
   "source": [
    "from langchain.prompts import ChatPromptTemplate, SystemMessagePromptTemplate, HumanMessagePromptTemplate\n",
    "\n",
    "prompt = ChatPromptTemplate.from_messages([\n",
    "    SystemMessagePromptTemplate.from_template(prompt_str),\n",
    "    HumanMessagePromptTemplate.from_template(\"{question}\")\n",
    "])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 58,
   "id": "03eb331e",
   "metadata": {},
   "outputs": [],
   "source": [
    "from langchain_core.runnables import RunnablePassthrough, RunnableParallel\n",
    "\n",
    "retriever_a = vecstore_a.as_retriever()\n",
    "retriever_b = vecstore_b.as_retriever()\n",
    "\n",
    "retrieval = RunnableParallel(\n",
    "    {\n",
    "        \"context_a\": retriever_a, \"context_b\": retriever_b, \"question\": RunnablePassthrough()\n",
    "    }\n",
    ")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "8e0ef089",
   "metadata": {},
   "source": [
    "La cadena que construiremos se verá algo como esto:\n",
    "\n",
    "![](https://github.com/aurelio-labs/langchain-course/blob/main/assets/lcel-flow.png?raw=1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 59,
   "id": "66c78520",
   "metadata": {},
   "outputs": [],
   "source": [
    "chain = retrieval | prompt | llm | output_parser"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c1b4a5ac",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'The DeepSeek-V3 model, released in December 2024, is a mixture of experts model with 671 billion parameters.'"
      ]
     },
     "execution_count": 60,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "result = chain.invoke(\n",
    "    \"what architecture does the model DeepSeek released in december use?\"\n",
    ")\n",
    "result"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python (modulo3 Credibanco)",
   "language": "python",
   "name": "modulo3-credibanco"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.7"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
